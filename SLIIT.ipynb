{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " Department ID                                   0\n",
      "Category ID                                     0\n",
      "Store ID                                        0\n",
      "Sale Quantity                                   0\n",
      "Gross Value for single Product (Single Sale)    0\n",
      "Retail Value (Single Sale)                      0\n",
      "Tax with Revenue                                0\n",
      "Cost                                            0\n",
      "Tax per unit                                    0\n",
      "TotalQTY                                        0\n",
      "TotalSales                                      0\n",
      "SalesDate                                       0\n",
      "Sales Time                                      0\n",
      "Buying price per product                        0\n",
      "dtype: int64\n",
      "float64\n",
      "1\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Retail Value for single Product (Single Sale)', 'TotalQTY'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 58\u001b[0m\n\u001b[0;32m     56\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m     57\u001b[0m numerical_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSale Quantity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGross Value for single Product (Single Sale)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetail Value for single Product (Single Sale)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCost\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTax per unit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotalQTY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotalSales\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuying price per product\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 58\u001b[0m sales_data[numerical_features] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43msales_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumerical_features\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Encode categorical variables using Label Encoding\u001b[39;00m\n\u001b[0;32m     61\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:3899\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3898\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3899\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3901\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6115\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6113\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6115\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6117\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6119\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6179\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6178\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6179\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Retail Value for single Product (Single Sale)', 'TotalQTY'] not in index\""
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Load datasets\n",
    "category_data = pd.read_csv('Category_Data.csv')\n",
    "department_data = pd.read_csv('Department_Data.csv')\n",
    "store_data = pd.read_csv('Store_Data.csv')\n",
    "sales_data = pd.read_csv('General Sales Data.csv')\n",
    "\n",
    "# Data Cleaning\n",
    "# Check for missing values\n",
    "missing_values = sales_data.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)\n",
    "\n",
    "# Handle missing values (replace with mean for numeric columns, mode for categorical columns)\n",
    "sales_data['Sale Quantity'].fillna(sales_data['Sale Quantity'].mean(), inplace=True)\n",
    "sales_data['Gross Value for single Product (Single Sale)'].fillna(sales_data['Gross Value for single Product (Single Sale)'].mean(), inplace=True)\n",
    "# Repeat for other relevant columns...\n",
    "\n",
    "# Identify and handle outliers\n",
    "# Assume 'Sale Quantity' and 'Gross Value for single Product (Single Sale)' are relevant columns for outlier detection\n",
    "sales_data = sales_data[(sales_data['Sale Quantity'] <= sales_data['Sale Quantity'].quantile(0.95)) & (sales_data['Gross Value for single Product (Single Sale)'] <= sales_data['Gross Value for single Product (Single Sale)'].quantile(0.95))]\n",
    "\n",
    "# Ensure consistency in date formats\n",
    "sales_data['SalesDate'] = pd.to_datetime(sales_data['SalesDate'])\n",
    "\n",
    "# Feature Engineering\n",
    "# Create new features: day of the week, month, year\n",
    "sales_data['DayOfWeek'] = sales_data['SalesDate'].dt.dayofweek\n",
    "sales_data['Month'] = sales_data['SalesDate'].dt.month\n",
    "sales_data['Year'] = sales_data['SalesDate'].dt.year\n",
    "\n",
    "# Convert relevant columns to numeric data types\n",
    "department_data['Department ID'] = pd.to_numeric(department_data['Department ID'], errors='coerce')\n",
    "sales_data['Department ID'] = sales_data['Department ID'].astype('int64')\n",
    "print(department_data['Department ID'].dtype)\n",
    "print(department_data['Department ID'].isnull().sum())\n",
    "print(np.isinf(department_data['Department ID']).sum())\n",
    "department_data = department_data.dropna(subset=['Department ID'])\n",
    "department_data = department_data[~np.isinf(department_data['Department ID'])]\n",
    "department_data = department_data.fillna({'Department ID': 0})\n",
    "department_data.loc[np.isinf(department_data['Department ID']), 'Department ID'] = 0\n",
    "department_data['Department ID'] = department_data['Department ID'].astype('int64')\n",
    "\n",
    "\n",
    "# Merge datasets\n",
    "sales_data = pd.merge(sales_data, category_data, on='Category ID', how='left')\n",
    "sales_data = pd.merge(sales_data, department_data, on='Department ID', how='left')\n",
    "sales_data = pd.merge(sales_data, store_data, on='Store ID', how='left')\n",
    "\n",
    "# Data Transformation\n",
    "# Apply normalization to relevant numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['Sale Quantity', 'Gross Value for single Product (Single Sale)', 'Retail Value for single Product (Single Sale)', 'Cost', 'Tax per unit', 'TotalQTY', 'TotalSales', 'Buying price per product']\n",
    "sales_data[numerical_features] = scaler.fit_transform(sales_data[numerical_features])\n",
    "\n",
    "# Encode categorical variables using Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_features = ['Category Name', 'Department Name', 'Store Name', 'Location']\n",
    "for feature in categorical_features:\n",
    "    sales_data[feature] = label_encoder.fit_transform(sales_data[feature])\n",
    "\n",
    "# Display the cleaned and transformed dataset\n",
    "sales_data.head()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have already loaded your datasets\n",
    "# For example:\n",
    "# department_data = pd.read_csv('Department_Data.csv')\n",
    "\n",
    "# Check for missing values\n",
    "missing_values_department = department_data.isnull().sum()\n",
    "print(\"Missing Values in Department Data:\\n\", missing_values_department)\n",
    "\n",
    "# Check for infinity (considering 'Department ID' is a numeric column)\n",
    "is_inf_mask = np.isinf(department_data['Department ID'])\n",
    "inf_values_department = department_data[is_inf_mask]\n",
    "print(\"Infinity Values in Department Data:\\n\", inf_values_department)\n",
    "\n",
    "# Handle missing values (replace with mean for numeric columns, mode for categorical columns)\n",
    "# Example: department_data['Department ID'].fillna(department_data['Department ID'].mean(), inplace=True)\n",
    "\n",
    "# Handle infinity values (replace with a specific value or drop the rows)\n",
    "# Example: department_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# or: department_data = department_data[~is_inf_mask]\n",
    "\n",
    "# Print data type and number of missing values for 'Department ID'\n",
    "print(department_data['Department ID'].dtype)\n",
    "print(department_data['Department ID'].isnull().sum())\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Descriptive Statistics\n",
    "descriptive_stats = sales_data.describe()\n",
    "print(\"Descriptive Statistics:\\n\", descriptive_stats)\n",
    "\n",
    "# Visualizations\n",
    "\n",
    "# Distribution of Sale Quantity\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(sales_data['Sale Quantity'], bins=30, kde=True)\n",
    "plt.title('Distribution of Sale Quantity')\n",
    "plt.xlabel('Sale Quantity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Correlation Heatmap\n",
    "correlation_matrix = sales_data.corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot of Sale Quantity by Category Name\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='Category Name', y='Sale Quantity', data=sales_data)\n",
    "plt.title('Sale Quantity by Category Name')\n",
    "plt.xlabel('Category Name')\n",
    "plt.ylabel('Sale Quantity')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Time-based Analysis\n",
    "sales_data['YearMonth'] = sales_data['SalesDate'].dt.to_period('M')\n",
    "monthly_sales = sales_data.groupby('YearMonth')['TotalSales'].sum()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "monthly_sales.plot(kind='line', marker='o')\n",
    "plt.title('Monthly Total Sales Over Time')\n",
    "plt.xlabel('Year-Month')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.show()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have already loaded your datasets\n",
    "# For example:\n",
    "# department_data = pd.read_csv('Department_Data.csv')\n",
    "\n",
    "# Check for missing values\n",
    "missing_values_department = department_data.isnull().sum()\n",
    "print(\"Missing Values in Department Data:\\n\", missing_values_department)\n",
    "\n",
    "# Check for infinity (considering 'Department ID' is a numeric column)\n",
    "numeric_columns = department_data.select_dtypes(include=np.number).columns\n",
    "for col in numeric_columns:\n",
    "    is_inf_mask = np.isinf(department_data[col])\n",
    "    inf_values_department = department_data[is_inf_mask]\n",
    "    print(f\"Infinity Values in {col} column:\\n\", inf_values_department)\n",
    "\n",
    "# Handle missing values (replace with mean for numeric columns, mode for categorical columns)\n",
    "# Example: department_data['Department ID'].fillna(department_data['Department ID'].mean(), inplace=True)\n",
    "\n",
    "# Print data type and number of missing values for 'Department ID'\n",
    "print(department_data['Department ID'].dtype)\n",
    "print(department_data['Department ID'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
